{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(토론-4) 어떤 model들을 ensemble하면 좋을까?](https://stages.ai/competitions/218/discussion/talk/post/1817)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 게시글에서는 어떤 모델들을 앙상블할 때 효과가 극대화하는지를 알아보고자 합니다.\n",
    "\n",
    "개인적으로 서로 다른 경향의 결과를 내는 모델들을 앙상블할 때 효과가 좋았을 때가 많았는데요, 이렇게 앙상블을 하기 위해서는 서로 다른 특성을 측정하는 것이 중요했습니다.\n",
    "\n",
    "여러 방법이 있을 수 있겠지만, 이번 대회에서는 많은 class가 있기 때문에, 여러 class에서 두루 좋은 성능을 낼 수 있도록 각 class 별 성능을 측정하여 object detection model들을 앙상블하는 방법을 시도해보면 어떨까?라는 생각을 하게 되었습니다.\n",
    "\n",
    "띠라서, class별 성능 (mAP)과 어떤 class와 어떤 class를 헷갈리는지 등을 파악해보기 위해 다음과 같은 코드를 작성해보았습니다. (참고: https://github.com/WongKinYiu/yolov7.git)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "from pycocotools.coco import COCO\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def box_iou_calc(boxes1, boxes2):\n",
    "    # <https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py>\n",
    "    \"\"\"\n",
    "    Return intersection-over-union (Jaccard index) of boxes.\n",
    "    Both sets of boxes are expected to be in (x1, y1, x2, y2) format.\n",
    "    Arguments:\n",
    "        boxes1 (Array[N, 4])\n",
    "        boxes2 (Array[M, 4])\n",
    "    Returns:\n",
    "        iou (Array[N, M]): the NxM matrix containing the pairwise\n",
    "            IoU values for every element in boxes1 and boxes2\n",
    "    This implementation is taken from the above link and changed so that it only uses numpy..\n",
    "    \"\"\"\n",
    "\n",
    "    def box_area(box):\n",
    "        # box = 4xn\n",
    "        return (box[2] - box[0]) * (box[3] - box[1])\n",
    "\n",
    "    area1 = box_area(boxes1.T)\n",
    "    area2 = box_area(boxes2.T)\n",
    "\n",
    "    lt = np.maximum(boxes1[:, None, :2], boxes2[:, :2])  # [N,M,2]\n",
    "    rb = np.minimum(boxes1[:, None, 2:], boxes2[:, 2:])  # [N,M,2]\n",
    "\n",
    "    inter = np.prod(np.clip(rb - lt, a_min=0, a_max=None), 2)\n",
    "    return inter / (\n",
    "        area1[:, None] + area2 - inter\n",
    "    )  # iou = inter / (area1 + area2 - inter)\n",
    "\n",
    "\n",
    "class ConfusionMatrix:\n",
    "    def __init__(self, num_classes: int, CONF_THRESHOLD=0.3, IOU_THRESHOLD=0.5):\n",
    "        self.matrix = np.zeros((num_classes + 1, num_classes + 1))\n",
    "        self.num_classes = num_classes\n",
    "        self.CONF_THRESHOLD = CONF_THRESHOLD\n",
    "        self.IOU_THRESHOLD = IOU_THRESHOLD\n",
    "\n",
    "    def plot(\n",
    "        self,\n",
    "        file_name=\"./\",\n",
    "        names=[\n",
    "            \"General trash\",\n",
    "            \"Paper\",\n",
    "            \"Paper pack\",\n",
    "            \"Metal\",\n",
    "            \"Glass\",\n",
    "            \"Plastic\",\n",
    "            \"Styrofoam\",\n",
    "            \"Plastic bag\",\n",
    "            \"Battery\",\n",
    "            \"Clothing\",\n",
    "        ],\n",
    "    ):\n",
    "        try:\n",
    "            import seaborn as sn\n",
    "\n",
    "            array = self.matrix / (\n",
    "                self.matrix.sum(0).reshape(1, self.num_classes + 1) + 1e-6\n",
    "            )  # normalize\n",
    "            array[array < 0.005] = np.nan  # don't annotate (would appear as 0.00)\n",
    "\n",
    "            fig = plt.figure(figsize=(12, 9), tight_layout=True)\n",
    "            sn.set(font_scale=1.0 if self.num_classes < 50 else 0.8)  # for label size\n",
    "            labels = (0 < len(names) < 99) and len(\n",
    "                names\n",
    "            ) == self.num_classes  # apply names to ticklabels\n",
    "            sn.heatmap(\n",
    "                array,\n",
    "                annot=self.num_classes < 30,\n",
    "                annot_kws={\"size\": 8},\n",
    "                cmap=\"Blues\",\n",
    "                fmt=\".2f\",\n",
    "                square=True,\n",
    "                xticklabels=names + [\"background FP\"] if labels else \"auto\",\n",
    "                yticklabels=names + [\"background FN\"] if labels else \"auto\",\n",
    "            ).set_facecolor((1, 1, 1))\n",
    "            fig.axes[0].set_xlabel(\"True\")\n",
    "            fig.axes[0].set_ylabel(\"Predicted\")\n",
    "            fig.savefig(Path(\"./result_analysis\") / file_name, dpi=250)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "    def process_batch(self, detections, labels: np.ndarray):\n",
    "        \"\"\"\n",
    "        Return intersection-over-union (Jaccard index) of boxes.\n",
    "        Both sets of boxes are expected to be in (x1, y1, x2, y2) format.\n",
    "        Arguments:\n",
    "            detections (Array[N, 6]), x1, y1, x2, y2, conf, class\n",
    "            labels (Array[M, 5]), class, x1, y1, x2, y2\n",
    "        Returns:\n",
    "            None, updates confusion matrix accordingly\n",
    "        \"\"\"\n",
    "        gt_classes = labels[:, 0].astype(np.int16)\n",
    "\n",
    "        try:\n",
    "            detections = detections[detections[:, 4] > self.CONF_THRESHOLD]\n",
    "        except IndexError or TypeError:\n",
    "            # detections are empty, end of process\n",
    "            for i, label in enumerate(labels):\n",
    "                gt_class = gt_classes[i]\n",
    "                self.matrix[self.num_classes, gt_class] += 1\n",
    "            return\n",
    "\n",
    "        detection_classes = detections[:, 5].astype(np.int16)\n",
    "\n",
    "        all_ious = box_iou_calc(labels[:, 1:], detections[:, :4])\n",
    "        want_idx = np.where(all_ious > self.IOU_THRESHOLD)\n",
    "\n",
    "        all_matches = [\n",
    "            [want_idx[0][i], want_idx[1][i], all_ious[want_idx[0][i], want_idx[1][i]]]\n",
    "            for i in range(want_idx[0].shape[0])\n",
    "        ]\n",
    "\n",
    "        all_matches = np.array(all_matches)\n",
    "        if all_matches.shape[0] > 0:  # if there is match\n",
    "            all_matches = all_matches[all_matches[:, 2].argsort()[::-1]]\n",
    "\n",
    "            all_matches = all_matches[\n",
    "                np.unique(all_matches[:, 1], return_index=True)[1]\n",
    "            ]\n",
    "\n",
    "            all_matches = all_matches[all_matches[:, 2].argsort()[::-1]]\n",
    "\n",
    "            all_matches = all_matches[\n",
    "                np.unique(all_matches[:, 0], return_index=True)[1]\n",
    "            ]\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            gt_class = gt_classes[i]\n",
    "            if (\n",
    "                all_matches.shape[0] > 0\n",
    "                and all_matches[all_matches[:, 0] == i].shape[0] == 1\n",
    "            ):\n",
    "                detection_class = detection_classes[\n",
    "                    int(all_matches[all_matches[:, 0] == i, 1][0])\n",
    "                ]\n",
    "                self.matrix[detection_class, gt_class] += 1\n",
    "            else:\n",
    "                self.matrix[self.num_classes, gt_class] += 1\n",
    "\n",
    "        for i, detection in enumerate(detections):\n",
    "            if not all_matches.shape[0] or (\n",
    "                all_matches.shape[0]\n",
    "                and all_matches[all_matches[:, 1] == i].shape[0] == 0\n",
    "            ):\n",
    "                detection_class = detection_classes[i]\n",
    "                self.matrix[detection_class, self.num_classes] += 1\n",
    "\n",
    "    def return_matrix(self):\n",
    "        return self.matrix\n",
    "\n",
    "    def print_matrix(self):\n",
    "        for i in range(self.num_classes + 1):\n",
    "            print(\" \".join(map(str, self.matrix[i])))\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    conf_mat = ConfusionMatrix(num_classes=10, CONF_THRESHOLD=0.01, IOU_THRESHOLD=0.5)\n",
    "    gt_path = args.gt_json\n",
    "    pred_path = args.pred_csv\n",
    "    with open(gt_path, \"r\") as outfile:\n",
    "        test_anno = json.load(outfile)\n",
    "\n",
    "    pred_df = pd.read_csv(pred_path)\n",
    "\n",
    "    new_pred = []\n",
    "\n",
    "    gt = []\n",
    "\n",
    "    file_names = pred_df[\"image_id\"].values.tolist()\n",
    "    bboxes = pred_df[\"PredictionString\"].values.tolist()\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        if isinstance(bbox, float):\n",
    "            print(f\"{file_names[i]} empty box\")\n",
    "\n",
    "    for file_name, bbox in tqdm(zip(file_names, bboxes)):\n",
    "        new_pred.append([])\n",
    "        boxes = np.array(str(bbox).split(\" \"))\n",
    "\n",
    "        if len(boxes) % 6 == 1:\n",
    "            boxes = boxes[:-1].reshape(-1, 6)\n",
    "        elif len(boxes) % 6 == 0:\n",
    "            boxes = boxes.reshape(-1, 6)\n",
    "        else:\n",
    "            raise Exception(\"error\", \"invalid box count\")\n",
    "        for box in boxes:\n",
    "            new_pred[-1].append(\n",
    "                [\n",
    "                    float(box[2]),\n",
    "                    float(box[3]),\n",
    "                    float(box[4]),\n",
    "                    float(box[5]),\n",
    "                    float(box[1]),\n",
    "                    float(box[0]),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    coco = COCO(gt_path)\n",
    "\n",
    "    for image_id in coco.getImgIds():\n",
    "        gt.append([])\n",
    "        image_info = coco.loadImgs(image_id)[0]\n",
    "        ann_ids = coco.getAnnIds(imgIds=image_info[\"id\"])\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "        file_name = image_info[\"file_name\"]\n",
    "\n",
    "        for ann in anns:\n",
    "            gt[-1].append(\n",
    "                [\n",
    "                    float(ann[\"category_id\"]),\n",
    "                    float(ann[\"bbox\"][0]),\n",
    "                    float(ann[\"bbox\"][1]),\n",
    "                    float(ann[\"bbox\"][0]) + float(ann[\"bbox\"][2]),\n",
    "                    (float(ann[\"bbox\"][1]) + float(ann[\"bbox\"][3])),\n",
    "                ]\n",
    "            )\n",
    "    for p, g in zip(new_pred, gt):\n",
    "        conf_mat.process_batch(np.array(p), np.array(g))\n",
    "    conf_mat.plot(args.file_name)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Process some integers.\")\n",
    "    parser.add_argument(\"--gt_json\", type=str)\n",
    "    parser.add_argument(\"--pred_csv\", type=str)\n",
    "    parser.add_argument(\n",
    "        \"--file_name\",\n",
    "        type=str,\n",
    "        default=\"confusion_matrix.png\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    main(args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드를 실행한 결과, 저는 다음과 같은 결과들을 얻을 수 있었고, 어떤 모델을 앙상블할 것인지 결정하는데에 참고할 수 있었습니다.\n",
    "\n",
    "![](https://s3-us-west-2.amazonaws.com/aistages-prod-server-public/app/Users/00000651/files/5268b4fb-51d0-464e-95bb-20042fff69db..png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러분은 어떤 모델들을 어떻게 앙상블 할 것인지 어떻게 결정하셨나요? 다른 좋은 방법이 있다면 공유 부탁드립니다. 😊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('detection-00')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9510b29cf32525666e80611a5ee39b10e564c90abecc36e9b870f07fd520482f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
